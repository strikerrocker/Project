{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866d4164",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential,Model\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Conv2D, Softmax, Dropout, Input, MaxPooling2D,GlobalAveragePooling2D,LeakyReLU,ZeroPadding2D,Reshape,Concatenate\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import CSVLogger, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from livelossplot import PlotLossesKeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83f8294-9b16-4efe-8835-95d8f3ceb2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 16\n",
    "MODEL_FILE = \"model.h5\"\n",
    "TRAINING_LOGS_FILE = \"training_logs.csv\"\n",
    "VERBOSITY = 1\n",
    "img_height = 277\n",
    "img_width = 277\n",
    "batch_size = 128\n",
    "data_path = \"../dataset/Cropped/\"\n",
    "train_output_directory = \"../dataset/Augmented/train/\"\n",
    "validation_output_directory = \"../dataset/Augmented/validation/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f793ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = Input(shape=(227, 227, 3), name=\"original_img\")\n",
    "# Left Most branch\n",
    "conv01 = Conv2D(64,(3,3),strides=2,padding='same')(input)\n",
    "leakyrelu01 = LeakyReLU(0.1)(conv01)\n",
    "batchnorm01 = BatchNormalization(epsilon=0.00001)(leakyrelu01)\n",
    "maxpool01 = MaxPooling2D(pool_size=6,strides=3,padding=\"same\")(batchnorm01)\n",
    "conv02 = Conv2D(128,(3,3),strides=2,padding='same')(maxpool01)\n",
    "leakyrelu02 = LeakyReLU(0.1)(conv02)\n",
    "batchnorm02 = BatchNormalization(epsilon=0.00001)(leakyrelu02)\n",
    "maxpool02 = MaxPooling2D(pool_size=(6,6),strides=3,padding='same')(batchnorm02)\n",
    "conv03 = Conv2D(224,(3,3),strides=2,padding='same')(maxpool02)\n",
    "leakyrelu03 = LeakyReLU(0.1)(conv03)\n",
    "batchnorm03 = BatchNormalization(epsilon=0.00001)(leakyrelu03)\n",
    "maxpool03 = MaxPooling2D(pool_size=(6,6),strides=3,padding='same')(batchnorm03)\n",
    "\n",
    "#Fully connected 1\n",
    "fc_reshape = Reshape((1, 1, -1))(input)\n",
    "fc01 = Dense(16, activation='relu')(fc_reshape)\n",
    "\n",
    "leakyrelu01_fc = LeakyReLU(0.1)(fc01)\n",
    "batchnorm01_fc = BatchNormalization(epsilon=0.00001)(leakyrelu01_fc)\n",
    "dropout01_fc = Dropout(0.2)(batchnorm01_fc)\n",
    "\n",
    "zeropadding01 = ZeroPadding2D(padding=(2, 2))(dropout01_fc)\n",
    "conv05 = Conv2D(64,(3,3),strides=2)(zeropadding01)\n",
    "leakyrelu05 = LeakyReLU(0.1)(conv05)\n",
    "batchnorm05 = BatchNormalization(epsilon=0.00001)(leakyrelu05)\n",
    "\n",
    "zeropadding02 = ZeroPadding2D(padding=(1, 1))(dropout01_fc)\n",
    "conv04 = Conv2D(32,(2,2),strides=1)(zeropadding02)\n",
    "leakyrelu04 = LeakyReLU(0.1)(conv04)\n",
    "batchnorm04 = BatchNormalization(epsilon=0.00001)(leakyrelu04)\n",
    "\n",
    "depthcat01 = Concatenate()([batchnorm04,batchnorm05])\n",
    "dropout02 = Dropout(0.2)(depthcat01)\n",
    "\n",
    "# Combine Both branches\n",
    "depthcat02 = Concatenate()([dropout02,maxpool03])\n",
    "dropout03 = Dropout(0.2)(depthcat02)\n",
    "conv07 = Conv2D(256,(1,1),strides=1,padding='same')(dropout03)\n",
    "leakyrelu07 = LeakyReLU(0.1)(conv07)\n",
    "batchnorm07 = BatchNormalization(epsilon=0.00001)(leakyrelu07)\n",
    "dropout07 = Dropout(0.3)(batchnorm07)\n",
    "\n",
    "fc02_reshape = Reshape((1, 1, -1))(dropout07)\n",
    "fc02 = Dense(512)(fc02_reshape)\n",
    "\n",
    "leakyrelu02_fc = LeakyReLU(0.1)(fc02)\n",
    "batchnorm02_fc = BatchNormalization(epsilon=0.00001)(leakyrelu02_fc)\n",
    "dropout02_fc = Dropout(0.3)(batchnorm02_fc)\n",
    "\n",
    "fc03 = Dense(4)(dropout02_fc)\n",
    "softmax = Softmax()(fc03)\n",
    "\n",
    "\n",
    "model = Model(input,softmax,name=\"CCCN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ec72b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.0001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a3f669",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "    rotation_range=10,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    validation_split=0.2) # set validation split\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    directory=data_path,\n",
    "    save_to_dir=train_output_directory,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training') # set as training data\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    directory=data_path,\n",
    "    save_to_dir=validation_output_directory,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation') # set as validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fdcd384-3f95-4133-8b67-52e4df5bec15",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_LAYERS_SIMPLIFIED = \"model_plot_simplified.png\"\n",
    "MODEL_LAYERS = \"model_plot.png\"\n",
    "\n",
    "# Plot the model layer and save it as a file\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "# SVG(model_to_dot(model).create(prog='dot', format='svg'))\n",
    "\n",
    "from keras.utils.vis_utils import plot_model\n",
    "plot_model(model, to_file=MODEL_LAYERS_SIMPLIFIED, show_shapes=True, show_layer_names=True, expand_nested=False)\n",
    "plot_model(model, to_file=MODEL_LAYERS, show_shapes=True, show_layer_names=True, expand_nested=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2849d39e-2fb8-4c84-8137-b60d786b1780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model on data generator \n",
    "history = model.fit(train_generator,\n",
    "          steps_per_epoch=len(train_generator),\n",
    "          validation_data=validation_generator,\n",
    "          validation_steps=len(validation_generator),\n",
    "          epochs=EPOCHS,\n",
    "          verbose=VERBOSITY,\n",
    "          callbacks=[PlotLossesKeras(),\n",
    "                     ModelCheckpoint(MODEL_FILE,\n",
    "                                     monitor='val_accuracy',\n",
    "                                     verbose=VERBOSITY,\n",
    "                                     save_best_only=True,\n",
    "                                     mode='max'),\n",
    "                     CSVLogger(TRAINING_LOGS_FILE,\n",
    "                               append=False,\n",
    "                               separator=',')\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c0cb7a-f85d-4f84-b08c-ce3fc014b5b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
